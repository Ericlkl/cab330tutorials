{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Regression Mining\n",
    "\n",
    "### What's on this week\n",
    "1. [Resuming from week 3](#resume)\n",
    "2. [Building your first logistic regression model](#build)\n",
    "3. [Understanding your logistic regression model](#viz)\n",
    "4. [Finding optimal hyperparameters with GridSearchCV](#gridsearch)\n",
    "5. [Feature selection](#fselect)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Important Changelog:\n",
    "* (25/07/2017) Made tutorial notes public.\n",
    "* (22/08/2017) Added details on understanding logistic regression model.\n",
    "\n",
    "The practical note for this week introduces you to regression mining in Python, particularly using logistic regression. Regressions are a class of linear models that learn coefficients associated with each variable/field and uses them to make predictions.\n",
    "\n",
    "**This tutorial notes is in experimental version. Please give us feedbacks and suggestions on how to make it better. Ask your tutor for any question and clarification.**\n",
    "\n",
    "## 1. Resuming from week 3 <a name=\"resume\"></a>\n",
    "Last week, we learned how to perform data mining with decision trees in Python. For this week, we will reuse the code for data preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from dm_tools import data_prep\n",
    "\n",
    "# preprocessing step\n",
    "df = data_prep()\n",
    "\n",
    "# train test split\n",
    "y = df['TargetB']\n",
    "X = df.drop(['TargetB'], axis=1)\n",
    "X_mat = X.as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mat, y, test_size=0.5, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building your logistic regression <a name=\"build\"></a>\n",
    "\n",
    "### 2.1. Scaling your input\n",
    "\n",
    "Regression models are sensitive to extreme or outlying values in the input space. Inputs with highly skewed or kurtotic distributions are often selected over inputs with better overall predictions. To avoid this problem, we should scale our inputs first before building our logistic regression model. In `sklearn`, this can easily be done using `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Building logistic regression\n",
    "Once we scaled our inputs, we are ready to build the model. There are a number of types of regression, namely linear and logistic. The type of regression to use is determined by the target's measurement level. In this case study, the target is of categorical type, thus we need to use logistic regression.\n",
    "\n",
    "Import and train your logistic regression using code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.601486681809\n",
      "Test accuracy: 0.560396448482\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.57      0.56      2422\n",
      "          1       0.56      0.56      0.56      2421\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score of this model is still below our tuned decision tree model from last week. We will tune this logistic regression model later using GridSearchCV.\n",
    "\n",
    "## 3. Understanding your logistic regression model\n",
    "\n",
    "Let's take a deeper look on the model we just built. Firstly, I want to gloss over what is logistic regression is doing. From the lecture, you know that a regression function looks like this:\n",
    "\n",
    "![regression](http://dataminingtuts.s3.amazonaws.com/reg%20func.png)\n",
    "\n",
    "As a model, the training process learns weight associated with each feature. The model will try to minimize the cost function, which basically says how far off our current predictions to the ground truth. It looks something like this.\n",
    "\n",
    "![cost function](http://www.holehouse.org/mlclass/06_Logistic_Regression_files/Image%20[16].png)\n",
    "\n",
    "In your logistic regression model, all of these weights are stored in `.coef_` array of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.33602653e-01  -3.49056089e-02   8.73566230e-02  -1.12651635e-02\n",
      "   -6.47840088e-02   1.13940905e-01  -4.12320034e-02  -1.23297590e-01\n",
      "   -2.08348018e-01   2.12149366e-01  -1.13710531e-01  -3.89598871e-02\n",
      "    2.30150906e-01  -8.31877872e-03   1.07410585e-01  -3.17911696e-01\n",
      "    4.52178040e-02   6.17079922e-02   8.77745248e-03   1.19286400e-01\n",
      "    3.75487610e-02   5.66886440e-03  -1.20892339e-02   5.39555436e-02\n",
      "   -1.70558014e-04   2.01003841e-02   2.42925060e-02  -2.05111807e-02\n",
      "    1.89149024e-02   5.05414793e-03  -4.65260744e-02  -3.38191227e-02\n",
      "   -1.41424074e-02  -1.67238887e-02   3.86303629e-02  -2.31226806e-02\n",
      "    1.11223079e-03   1.70336618e-02   2.46588520e-02   2.35854693e-02\n",
      "   -9.61325920e-03  -1.73118549e-02  -3.34528413e-02   3.19422613e-03\n",
      "    3.89319530e-02   2.18523161e-02  -1.98122166e-02   3.68602924e-03\n",
      "   -1.87540268e-02   5.99883634e-02   3.15149380e-02   2.21313816e-02\n",
      "   -7.55713758e-02   4.65482060e-02  -2.58371669e-02  -5.99349056e-03\n",
      "    1.52829815e-02   2.10342994e-02  -4.30148465e-02  -3.78855602e-03\n",
      "    3.03614466e-02   1.88929353e-02   4.69645018e-02   3.57621861e-02\n",
      "   -3.46544935e-02   6.68839088e-02  -5.38305475e-02  -9.01121871e-02\n",
      "    6.76933675e-03   2.42061415e-02  -8.45577154e-03  -1.52324651e-03\n",
      "   -1.08423602e-02  -3.95632506e-02  -1.28127945e-02   3.47869428e-03\n",
      "   -1.29983641e-03   8.40245281e-02  -1.44868947e-02   5.33742211e-02\n",
      "   -5.29184247e-03  -4.97155807e-02  -1.84483202e-02   1.75364140e-02\n",
      "    2.56637982e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could print out feature name associated with each coefficient with this code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GiftCnt36 : 0.133602653199\n",
      "GiftCntAll : -0.0349056089497\n",
      "GiftCntCard36 : 0.087356622996\n",
      "GiftCntCardAll : -0.0112651635391\n",
      "GiftAvgLast : -0.0647840088247\n",
      "GiftAvg36 : 0.113940905339\n",
      "GiftAvgAll : -0.0412320034172\n",
      "GiftAvgCard36 : -0.123297589673\n",
      "GiftTimeLast : -0.208348018158\n",
      "GiftTimeFirst : 0.212149366016\n",
      "PromCnt12 : -0.113710531176\n",
      "PromCnt36 : -0.0389598870799\n",
      "PromCntAll : 0.230150906116\n",
      "PromCntCard12 : -0.00831877871842\n",
      "PromCntCard36 : 0.10741058488\n",
      "PromCntCardAll : -0.317911696441\n",
      "StatusCatStarAll : 0.0452178040204\n",
      "DemAge : 0.0617079921947\n",
      "DemHomeOwner : 0.00877745248472\n",
      "DemMedHomeValue : 0.119286399816\n"
     ]
    }
   ],
   "source": [
    "feature_names = X.columns\n",
    "coef = model.coef_[0]\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "coef = coef[:20]\n",
    "\n",
    "for i in range(len(coef)):\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive coefficient means positive change in the input feature has positive correlation to the prediction value. Negative coefficient does the reverse. For example, DemAge has positive coefficient, which means older donors are predicted to be more likely to donate back. On the other hand, GiftTimeLast has negative coefficient, thus the model predicts the longer a donor donated last shrinks the possibility of donating back.\n",
    "\n",
    "Now, because a regression is a mathematical function, how can it predict classification problems? The answer lies in the word logistic. Logistic is a function that looks like this:\n",
    "\n",
    "![logistic](http://dataminingtuts.s3.amazonaws.com/logistic_function.png)\n",
    "\n",
    "Logistic function produces output from 0 to 1. The output curve looks like this\n",
    "\n",
    "![logistic curve](http://dataminingtuts.s3.amazonaws.com/Logistic-curve.svg.png)\n",
    "\n",
    "In a logistic regression model, all inputs smaller than 0.5 will be classified as 0 and the rest as 1. We can then use this function for making classification predictions.\n",
    "\n",
    "Another question often asked in interpreting a regression model is which features are most important? One way to answer the question is to use the coefficients. Changes in important variables (either positive or negative) should produce large impact to the predictions. Thus, we should look at the largest absolute coefficients to give us clues of which variables are important.\n",
    "\n",
    "**NOTE: This only applies to regression on standarised features. Without standarisation, each feature can have different scales, where coefficients do not help in interpreting the impact a feature has on the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PromCntCardAll : -0.317911696441\n",
      "PromCntAll : 0.230150906116\n",
      "GiftTimeFirst : 0.212149366016\n",
      "GiftTimeLast : -0.208348018158\n",
      "GiftCnt36 : 0.133602653199\n",
      "GiftAvgCard36 : -0.123297589673\n",
      "DemMedHomeValue : 0.119286399816\n",
      "GiftAvg36 : 0.113940905339\n",
      "PromCnt12 : -0.113710531176\n",
      "PromCntCard36 : 0.10741058488\n",
      "DemCluster_44 : -0.0901121870588\n",
      "GiftCntCard36 : 0.087356622996\n",
      "DemCluster_53 : 0.0840245280836\n",
      "DemCluster_30 : -0.0755713757994\n",
      "DemCluster_42 : 0.0668839087909\n",
      "GiftAvgLast : -0.0647840088247\n",
      "DemAge : 0.0617079921947\n",
      "DemCluster_28 : 0.0599883634188\n",
      "StatusCat96NK_E : 0.0539555435531\n",
      "DemCluster_43 : -0.0538305475468\n"
     ]
    }
   ],
   "source": [
    "# grab feature importances from the model and feature name from the original X\n",
    "coef = model.coef_[0]\n",
    "feature_names = X.columns\n",
    "\n",
    "# sort them out in descending order\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "# limit to 20 features, you can leave this out to print out everything\n",
    "indices = indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], ':', coef[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finding optimal hyperparameters with GridSearchCV\n",
    "\n",
    "Alright, let's see whether we can tune our logistic regression model to be better. In this example, I will tune it using only one parameter, `C`, which is the inverse of regularization strength. Smaller values specify stronger regularization. Typical values for C range from 10^-6 to 10^4, increasing in order or 10, which is what we will use here.\n",
    "\n",
    "Tips: sometimes `GridSearchCV` can be very slow if we are searching over a large set of possible values. To aid with this problem, `GridSearchCV` is implemented with parallel running capability and you can specify how many parallel processes running in the same time with `n_jobs` (-1 means GridSearchCV will use as many cores as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.581664257692\n",
      "Test accuracy: 0.569275242618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.60      0.58      2422\n",
      "          1       0.57      0.54      0.56      2421\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4843\n",
      "\n",
      "{'C': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our GridSearchCV shows improvement with `C` = 0.0001 compared to the original `C`. This is the best result so far compared to decision trees and we will keep it. Experiment with other set of values and parameters, and see if you can get a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Dimensionality reduction\n",
    "\n",
    "Another method to improve prediction quality from a model is to perform dimensionality reduction on the input set. Dimensionality reduction is divided into two processes:\n",
    "* Feature selection: Process of selecting a subset of relevant features/variables to be used in constructing models.\n",
    "* Feature extraction: Process of transforming high-dimensional feature space into lower dimension. Typically performed by finding principle components of the feature space.\n",
    "\n",
    "Let's explore some dimensionality reduction techniques. \n",
    "\n",
    "### 5.1. Recursive feature elimination\n",
    "\n",
    "The first method that we will try is called recursive feature elimination (RFE). RFE works by first training the model on the whole set of features. Each feature then will be assigned an weight and RFE tries to eliminate and make a smaller feature set.\n",
    "\n",
    "In this tutorial, we will use RFE with cross validation. The cross validation allows the RFE to be generalized better. Firstly, let's import `RFECV` from `sklearn.feature_selection`. Initiate the RFE with a logistic regression estimator and 10-fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature set (4843, 85)\n",
      "Number of features after elimination 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfe = RFECV(estimator = LogisticRegression(), cv=10)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "print(\"Original feature set\", X_train.shape)\n",
    "print(\"Number of features after elimination\", rfe.n_features_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the RFE is fitted, we can transform the original feature set using `.transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sel = rfe.transform(X_train)\n",
    "X_test_sel = rfe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to reduce the feature set from 85 to 19. Let's re-tune the logistic regression model with this new feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.588271732397\n",
      "Test accuracy: 0.570514144126\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.59      0.58      2422\n",
      "          1       0.57      0.55      0.56      2421\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4843\n",
      "\n",
      "{'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_sel, y_train)\n",
    "\n",
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train_sel, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test_sel, y_test))\n",
    "\n",
    "y_pred = cv.predict(X_test_sel)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RFE managed to improve the performance slightly. In addition to that, with much smaller feature set, the training process is speed up significantly.\n",
    "\n",
    "### 5.2. Principle Component Analysis\n",
    "\n",
    "Principal Components Analysis (PCA) is a technique that finds underlying variables (known as principal components) that best differentiate your data points. The idea of PCA is to reduce the number of features while still retaining the variance/pattern in the feature set.\n",
    "\n",
    "[Intuitive explanation of PCA](https://www.quora.com/What-is-an-intuitive-explanation-for-PCA)\n",
    "\n",
    "Let's start by importing `PCA` from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PCA, we need to specify the number of components that we want to retain. The problem is, how do we know how many? A good rule of thumb is to ensure at least 95% of the variance ratio is retained. Firstly, start by fitting the PCA using X_train. Then, iterate through the `explained_variance_ratio` from the PCA model, and start summing them until it reached at least 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N components with > 95% variance = 66\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "\n",
    "sum_var = 0\n",
    "for idx, val in enumerate(pca.explained_variance_ratio_):\n",
    "    sum_var += val\n",
    "    if (sum_var >= 0.95):\n",
    "        print(\"N components with > 95% variance =\", idx+1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we know we need to retain 66 components to retain at least 95%. Let's refit the PCA with 66 components and retune the logistic regression model to see if the PCA improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.580012389015\n",
      "Test accuracy: 0.570514144126\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.60      0.58      2422\n",
      "          1       0.58      0.54      0.56      2421\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4843\n",
      "\n",
      "{'C': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=66)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# grid search CV\n",
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_pca, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test_pca, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test_pca)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows an improved performance over the original feature set. We also managed to reduce the feature set size to only 66, which shorten the training process.\n",
    "\n",
    "One disadvantage of PCA is it is a statistical procedure that transforms the original features into a completely different set. Thus, all of the original fields/columns are gone and you cannot interpret it as in original.\n",
    "\n",
    "### 5.3. Feature selection using model\n",
    "\n",
    "The last method that we will try on this dataset is the select from model. In this technique, we utilise machine learning models with ability to find feature importance and select the feature set using that computed importance. Typically, decision tree or support vector machine models are used in this method. We will use decision tree here.\n",
    "\n",
    "Firstly, let's tune another decision tree using the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': range(3, 10), 'min_samples_leaf': range(20, 200, 20)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': range(3, 10),\n",
    "          'min_samples_leaf': range(20, 200, 20)}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=DecisionTreeClassifier(), cv=10)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we could analyse the feature importance from this trained model. Remember the `analyse_feature_importance` method we wrote last week? We will use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GiftAvgLast : 0.424147866229\n",
      "DemMedHomeValue : 0.17874460397\n",
      "GiftTimeLast : 0.135715271083\n",
      "GiftAvgCard36 : 0.0996893965541\n",
      "DemAge : 0.0654544865005\n",
      "PromCntCard36 : 0.0494236862349\n",
      "GiftCntAll : 0.0468246894295\n",
      "DemGender_U : 0.0\n",
      "DemCluster_11 : 0.0\n",
      "StatusCat96NK_N : 0.0\n",
      "StatusCat96NK_S : 0.0\n",
      "DemCluster_0 : 0.0\n",
      "DemCluster_1 : 0.0\n",
      "DemCluster_10 : 0.0\n",
      "DemCluster_13 : 0.0\n",
      "DemCluster_12 : 0.0\n",
      "StatusCat96NK_F : 0.0\n",
      "DemCluster_14 : 0.0\n",
      "DemCluster_15 : 0.0\n",
      "DemCluster_16 : 0.0\n"
     ]
    }
   ],
   "source": [
    "from dm_tools import analyse_feature_importance\n",
    "\n",
    "analyse_feature_importance(cv.best_estimator_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature importance analysis result shows there are only 7 features with importance value more than 0. This means according to our decision tree, there are only 7 important features in our feature set. Let's use this decision tree to select our features. We will use `SelectFromModel` module from `sklearn.feature_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4843, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "selectmodel = SelectFromModel(cv.best_estimator_, prefit=True)\n",
    "X_train_sel_model = selectmodel.transform(X_train)\n",
    "X_test_sel_model = selectmodel.transform(X_test)\n",
    "\n",
    "print(X_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of X_train shows there are only 7 feature left, exactly what the decision tree suggests. Let's train and tune another logistic regression model from this new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.570927111295\n",
      "Test accuracy: 0.572578979971\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.58      0.58      2422\n",
      "          1       0.57      0.56      0.57      2421\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4843\n",
      "\n",
      "{'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "params = {'C': [pow(10, x) for x in range(-6, 4)]}\n",
    "\n",
    "cv = GridSearchCV(param_grid=params, estimator=LogisticRegression(), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train_sel_model, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv.score(X_train_sel_model, y_train))\n",
    "print(\"Test accuracy:\", cv.score(X_test_sel_model, y_test))\n",
    "\n",
    "# test the best model\n",
    "y_pred = cv.predict(X_test_sel_model)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy result shows improvement over the original feature set as well. This method yields the smallest feature set yet (only 7 rather than 85 features), yet the performance is the best compared to the others. This demonstrates the effectiveness of dimensionality reduction.\n",
    "\n",
    "## End notes and next week\n",
    "\n",
    "This week, we learned how to build, tune and explore the structure of logistic regression models. We also explored dimensionality reduction techniques to reduce the size of the feature set and improve performance of our logistic regression model.\n",
    "\n",
    "Next week, we will learn how to perform predictive modelling with neural networks and comparing the end-to-end performance of all the models we have built so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
