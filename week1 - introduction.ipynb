{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Installing and Introduction to Python's Data Mining Libraries\n",
    "\n",
    "### What's on this week\n",
    "1. [Why Python?](#whypython)\n",
    "2. [Installing Anaconda](#install)\n",
    "3. [Process flow of predictive mining in Python](#processflow)\n",
    "4. [Interactive prototyping in ipython](#ipython)\n",
    "5. [Defining problem and purpose of data mining](#purpose)\n",
    "---\n",
    "\n",
    "### Important Changelog:\n",
    "* (25/07/2017) Made tutorial notes public.\n",
    "* (26/07/2017) Small changes on instructions to run IPython on Windows.\n",
    "* (02/11/2017) Large updates. Set notes to beta.\n",
    "\n",
    "The practical note for this week introduces you to Python and its common machine learning libraries. Python is a high-level, interpreted programming language. It is used for wide range of purposes, from web servers to scientific computing. Its syntax emphasizes on readibility, which allow anyone to learn and use it quickly.\n",
    "\n",
    "The practical sessions in this unit will be covering the usage of Python for data mining and machine learning purposes. We **WILL NOT ** cover the basics of Python. Fortunately, there is a lot of resources for learning Python from scratch, and you can reasonably learn the basics in a week.\n",
    "\n",
    "We will use Python 3 in this unit. All examples are written using Python 3.5.2, but any version of Python 3 above 3.4 should work just fine. \n",
    "\n",
    "**This tutorial notes is in beta version. Please give us feedbacks and suggestions on how to make it better. Ask your tutor for any question and clarification.**\n",
    "\n",
    "\n",
    "\n",
    "## 1. Why Python? <a name=\"whypython\"></a>\n",
    "In the field of data mining/machine learning, Python is arguably the fastest growing and most widely used programming language alongside R and Julia. There are a number of reasons for this:\n",
    "\n",
    "### 1.1. Interpreted language\n",
    "Python is designed as an interpreted language, which allow users to test and prototype models really quickly.\n",
    "\n",
    "### 1.2. Open-source\n",
    "Python is free and has no ties to any propertiary/corporate technologies, which makes Python the top choice for students, academics and startups.\n",
    "\n",
    "### 1.3. Wide, cutting edge support for almost anything\n",
    "\n",
    "Vast range of actively updated libraries for almost every data mining task.\n",
    "\n",
    "* **pandas** for data wrangling and preprocessing ([link](http://pandas.pydata.org/))\n",
    "* **scikit-learn** for supervised and unsupervised learning ([link](http://scikit-learn.org/stable/))\n",
    "* **numpy** for matrix manipulation ([link](http://www.numpy.org/))\n",
    "* **seaborn** and **matplotlib** for visualization ([link](https://seaborn.pydata.org/)) ([link2](https://matplotlib.org/))\n",
    "* **ipython** for interactive prototyping ([link](https://ipython.org/))\n",
    "* **jupyter notebook** for interactive, web-based prototyping ([link](http://jupyter.org/))\n",
    "\n",
    "\n",
    "### 1.4. Production ready\n",
    "Models and pipelines built with Python are very suitable to deployment in production systems.\n",
    "\n",
    "## 2. Installing Anaconda <a name=\"install\"></a>\n",
    "\n",
    "Anaconda is a data science package for Python. It contains many essential data science libraries and is aimed to simplify the installation process. All libraries mentioned above are in Anaconda distribution except for Seaborn.\n",
    "\n",
    "### 2.1. For Windows/Mac Users\n",
    "\n",
    "For Windows users, simply download Anaconda and install it [link](https://www.anaconda.com/download/). Choose the latest Python3 version for Windows. Once you installed it, go to Start-Anaconda3-Anaconda Prompt. Type `conda install seaborn` to install Seaborn.\n",
    "\n",
    "\n",
    "### 2.2. For Linux Users\n",
    "\n",
    "For Linux users, go to Anaconda website to get the installation file [link](https://www.anaconda.com/download/). Choose the latest Python3 version. It should download an `.sh` file. Once the download process is finished, open your terminal and give execution permission with command `chmod +x [path_to_the_downloaded file]`. Run it to install by `./[path_to_downloaded file]`.\n",
    "\n",
    "## 3. Process flow for predictive mining using Python<a name=\"processflow\"></a>\n",
    "![Predictive mining process flow in Python](https://s3-ap-southeast-2.amazonaws.com/dataminingtuts/process_flow_python.png  \"Predictive mining process flow in Python\")\n",
    "\n",
    "The diagram above presents the steps we will take in this unit to perform predictive mining on the dataset. The first and most important step is to define problem and purpose of the data mining. You need to ask questions such as:\n",
    "\n",
    "* What kind of data do we have?\n",
    "* Why are we performing predictive mining on this data?\n",
    "* What information are we trying to predict?\n",
    "* How could the stakeholders (including yourself) use the insights we gained from the data mining?\n",
    "\n",
    "After we understand the problem and purpose of the data mining process, next step is to explore the data. In this step, we try to understand patterns and distributions in the data. We should also identifies problems in the dataset, such as noise and missing values, to be cleaned and processed out in the next step. Both steps will be performed mainly using ```pandas``` with some help from ```sklearn```'s preprocessing modules.\n",
    "\n",
    "Once the data is clean, it can be used to built predictive models. There are many algorithms available in ```sklearn```, each with its own characteristics. We will explore one algorithm at a time in the upcoming weeks.\n",
    "\n",
    "In all stages, we also need to visualize the patterns and trends found in the data. Visualization allows us to understand the data better. In this unit, all visualizations will be done using ```seaborn``` and ```matplotlib``` with data presented by ```pandas``` dataframes.\n",
    "\n",
    "\n",
    "## 4. Interactive prototyping with ipython<a name=\"ipython\"></a>\n",
    "\n",
    "```ipython``` is an interactive Python shell designed for fast prototyping. In data mining/machine learning, many engineers use ipython to quickly review the data and process they are working on.\n",
    "\n",
    "### For you who are using Anaconda\n",
    "\n",
    "To start the ipython console, go to Start-Anaconda3-IPython. It will start by default on your document folder. If you wish to save your projects on another directory, change the current directory using `cd \"your directory path\"`.\n",
    "\n",
    "![Starting IPython from Anaconda in Windows](http://dataminingtuts.s3.amazonaws.com/anaconda_ipython.png \"Starting IPython from Anaconda in Windows\")\n",
    "\n",
    "### For you who are using Linux/Unix and installed the libraries manually\n",
    "\n",
    "We can call ipython the same way as we call the python interpreter itself:\n",
    "\n",
    "```bash\n",
    "ipython\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Output\n",
    "Python 3.5.2 (default, Nov 17 2016, 17:05:23) \n",
    "Type 'copyright', 'credits' or 'license' for more information\n",
    "IPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.\n",
    "\n",
    "In [1]: \n",
    "```\n",
    "\n",
    "All examples in this unit are shown using ipython console.\n",
    "\n",
    "## 5. Defining problem and purpose of data mining process<a name=\"purpose\"></a>\n",
    "\n",
    "**Scenario:** A national veterans organisation is seeking to improve their donation solicitations targeting. By only soliciting the most likely donors, less money will be spent on solicitation efforts and more money will be available for charitable concerns. Of particular interest is the class of individuals identified as lapsing donors. They have ran a greeting card mailing campaign called **PVA97NK**. The organisation now seeks to classify its lapsing donors based on their responses to this campaign. With this classification, a decision can be made to either solicit or ignore a lapsing individual in next year campaign.\n",
    "\n",
    "Now it is up to you, as a data science professional employed by this organisation, to use this dataset to improve their solicitation effort.\n",
    "\n",
    "The `PVA97NK` dataset is available in `dataset/pva97nk.csv` file. Let's start to determine the answer the essential questions above by exploring the data. Import the dataset into our `ipython` console with `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('datasets/pva97nk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is imported, we can start by looking at the columns/variables available. We can use `.info()` function for this purpose.\n",
    "\n",
    "> **pandas.DataFrame.info()** provide concise summary of a DataFrame, such as number of entries (rows), data columns and their respective data types and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9686 entries, 0 to 9685\n",
      "Data columns (total 28 columns):\n",
      "TargetB             9686 non-null int64\n",
      "ID                  9686 non-null int64\n",
      "TargetD             4843 non-null float64\n",
      "GiftCnt36           9686 non-null int64\n",
      "GiftCntAll          9686 non-null int64\n",
      "GiftCntCard36       9686 non-null int64\n",
      "GiftCntCardAll      9686 non-null int64\n",
      "GiftAvgLast         9686 non-null float64\n",
      "GiftAvg36           9686 non-null float64\n",
      "GiftAvgAll          9686 non-null float64\n",
      "GiftAvgCard36       7906 non-null float64\n",
      "GiftTimeLast        9686 non-null int64\n",
      "GiftTimeFirst       9686 non-null int64\n",
      "PromCnt12           9686 non-null int64\n",
      "PromCnt36           9686 non-null int64\n",
      "PromCntAll          9686 non-null int64\n",
      "PromCntCard12       9686 non-null int64\n",
      "PromCntCard36       9686 non-null int64\n",
      "PromCntCardAll      9686 non-null int64\n",
      "StatusCat96NK       9686 non-null object\n",
      "StatusCatStarAll    9686 non-null int64\n",
      "DemCluster          9686 non-null int64\n",
      "DemAge              7279 non-null float64\n",
      "DemGender           9686 non-null object\n",
      "DemHomeOwner        9686 non-null object\n",
      "DemMedHomeValue     9686 non-null int64\n",
      "DemPctVeterans      9686 non-null int64\n",
      "DemMedIncome        9686 non-null int64\n",
      "dtypes: float64(6), int64(19), object(3)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PVA97NK dataset contains 29 columns/variables including ID, demographics of members, donation history of members, etc. There are two possible target variables that we are looking to predict:\n",
    "1. **TARGETB**: binary of whether a person is a lapsing donor or not.\n",
    "2. **TARGETD**: interval value of amount of donation given in response to the mailing campaign.\n",
    "\n",
    "With these information, we could now answer the questions listed in section 3:\n",
    "* **What kind of data do we have?**: 29 variables with various information about the donors.\n",
    "* **Why are we performing predictive mining on this data?**: We would like to find possible lapsing donors to improve our donation solicitation campaign.\n",
    "* **What information are we trying to predict?**: Whether a person is a possible lapsing donor or not, corresponding to **TARGETB**.\n",
    "* **How could the stakeholders (including yourself) use the insights we gained from the data mining?**:\n",
    "    1. Improved accuracy of the solicitation campaign, which result in higher response rate and less wasted effort.\n",
    "    2. Find underlying characteristics of lapsing donors, leading to better understanding of what makes donors return.\n",
    "\n",
    "Looks like we have got an interesting and useful data mining project in hand. :)\n",
    "\n",
    "## End notes and next week\n",
    "This week, we learned how to install Python and its libraries with Anaconda. We also learned about the typical data mining process flow in Python and explored a bit of the dataset to understand why we are performing data mining on it.\n",
    "\n",
    "Next week, we will focus on exploring trends and performing data cleaning/preprocessing on the PVA97NK dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
